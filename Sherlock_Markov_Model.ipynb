{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11f8f0e1",
   "metadata": {},
   "source": [
    "# Sherlock Holmes Story Generator using HMMs\n",
    "\n",
    "This notebook provides a walkthrough of Hidden Markov Modeling implementation for generating Sherlock Holmes stories.\n",
    "We will use pure python and Natural Language ToolKit (NLTK) library to preprocess the data for building our Hidden Markov Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4d1ed8",
   "metadata": {},
   "source": [
    "## Importing tools\n",
    "\n",
    "These are the given libraries that we will be using:\n",
    "* os: We use os library to create and specify the path for our dataset\n",
    "* re: We use re to be able to use Regex functionality in python.\n",
    "* nltk: The main library for interpreting our textual data. We will use it to tokeanize our text words\n",
    "* random: We will use random to randomize our data generation\n",
    "* glob: We use glob as a helper library to specify paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91559c7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:56:40.534989Z",
     "start_time": "2023-08-17T12:56:40.511644Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import random\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8843be7",
   "metadata": {},
   "source": [
    "## Importing the SH dataset\n",
    "\n",
    "The dataset that we use is called [Sherlock Holmes Stories](https://www.kaggle.com/datasets/idevji1/sherlock-holmes-stories) which is a collection of 67 files that contain Sherlock Holmes stories in a txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92ca1adf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:56:43.556920Z",
     "start_time": "2023-08-17T12:56:43.422989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines: 215021\n"
     ]
    }
   ],
   "source": [
    "data_path = 'dataset/sherlock/'\n",
    "\n",
    "\n",
    "def read_sh(data_path):\n",
    "    txt = []\n",
    "    file_paths = glob.glob(os.path.join(data_path, '*'))\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line == '----------':\n",
    "                    break\n",
    "                if line:\n",
    "                    txt.append(line)\n",
    "\n",
    "    return txt\n",
    "\n",
    "\n",
    "sherlock_stories = read_sh(data_path)\n",
    "print(f\"Number of lines: {len(sherlock_stories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdb7568",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "To feed the data into our HMM model we need to clean it up. \n",
    "1. We convert all characters to lower\n",
    "2. Remove special characters and replace it with '' (empty string) using regex\n",
    "3. Convert the lines into tokens\n",
    "4. Save only the tokens that are alphanumeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc79f770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:57:01.456026Z",
     "start_time": "2023-08-17T12:56:45.122752Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Nifdi\n",
      "[nltk_data]     Guliyev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 2332110\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "def clean_data(data):\n",
    "    cleaned_data = []\n",
    "    for line in data:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\",line)  # Replaces all the given characters with empty string \"\"\n",
    "        tokens = word_tokenize(line)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_data+=words\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_stories=clean_data(sherlock_stories)\n",
    "print(f\"Number of words: {len(cleaned_stories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f0b385",
   "metadata": {},
   "source": [
    "## The HMM Model\n",
    "\n",
    "**Prepare the Empty Model**: Start with an empty book where you'll jot down how words tend to follow each other.\n",
    "\n",
    "**Read the Data**: Go through the cleaned data word by word (or element by element).\n",
    "\n",
    "**Create State Pairs**: For each word, pick the current word and the word that comes after it. This pair is your \"current state\" and \"next state\". Imagine you're looking at two words at a time.\n",
    "\n",
    "**Count Transitions**: Keep track of how many times you've seen each pair of words as you read through the data. This helps you understand which words tend to follow others.\n",
    "\n",
    "**Calculate Probabilities**: After reading the data, go back to each pair of words you saw and calculate the chances of going from the current word to the next word. It's like figuring out how often each transition happens.\n",
    "\n",
    "**Done!**: Your book now has information about which words often come after other words. This can help you make new sentences that sound like the original data.\n",
    "\n",
    "Let's use a simple example to illustrate:\n",
    "\n",
    "Suppose we have cleaned data: `['A', 'B', 'C', 'A', 'B', 'D']` and we're creating a Markov model with an n_gram of 2.\n",
    "\n",
    "* You start with an empty book (dictionary).\n",
    "* You read the data in pairs: `('A', 'B')`, `('B', 'C')`, `('C', 'A')`, `('A', 'B')`, `('B', 'D')`.\n",
    "* You count the transitions: `('A', 'B')` appears twice, `('B', 'C')` appears once, `('C', 'A')` appears once, and so on.\n",
    "* You calculate the probabilities: `('A', 'B')` has a 100% chance (2 out of 2 times), `('B', 'C')` has 100% chance (1 out of 1 time), and so on.\n",
    "Your book now looks like:\n",
    "\n",
    "`{'A': {'B': 1.0},\n",
    "  'B': {'C': 1.0, 'D': 0.5, 'A': 0.5},\n",
    "  'C': {'A': 1.0}}`\n",
    "  \n",
    "This means that if you start with 'A', you'll probably go to 'B'. If you start with 'B', you might go to 'C' or 'D'. If you start with 'C', you'll probably go to 'A'. This information helps you generate new sequences that are likely to sound similar to the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53b83bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:57:01.480805Z",
     "start_time": "2023-08-17T12:57:01.456026Z"
    }
   },
   "outputs": [],
   "source": [
    "def markov_model_builder(cleaned_data, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_data)-n_gram-1):\n",
    "        current_state, next_state = '', ''\n",
    "        for j in range(n_gram):\n",
    "            current_state += cleaned_data[i+j] + ' '\n",
    "            next_state += cleaned_data[i+j+n_gram] + ' '\n",
    "        current_state  = current_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        \n",
    "        if current_state not in markov_model:\n",
    "            markov_model[current_state] = {}\n",
    "            markov_model[current_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[current_state]:\n",
    "                markov_model[current_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[current_state][next_state] = 1\n",
    "        \n",
    "    for current_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[current_state][state] = count/total\n",
    "    \n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79247bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:57:05.162701Z",
     "start_time": "2023-08-17T12:57:01.482944Z"
    }
   },
   "outputs": [],
   "source": [
    "markov_model = markov_model_builder(cleaned_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba1e74bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:57:05.183728Z",
     "start_time": "2023-08-17T12:57:05.162701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 208670\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of states: {len(markov_model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ca809e9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T12:57:05.357970Z",
     "start_time": "2023-08-17T12:57:05.185955Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible transitions from 'i am' state: \n",
      " {'glad you': 0.004316546762589928, 'sorry one': 0.0008633093525179857, 'clearing out': 0.0008633093525179857, 'warned off': 0.0008633093525179857, 'going to': 0.007194244604316547, 'sure the': 0.002014388489208633, 'sure there': 0.0008633093525179857, 'not the': 0.0017266187050359713, 'ready to': 0.0057553956834532375, 'not so': 0.004028776978417266, 'sorry for': 0.0028776978417266188, 'obliged to': 0.0028776978417266188, 'afraid you': 0.0008633093525179857, 'here but': 0.0008633093525179857, 'wondering watson': 0.0008633093525179857, 'mr nathan': 0.0008633093525179857, 'not too': 0.0008633093525179857, 'unable to': 0.005179856115107914, 'not a': 0.010071942446043165, 'a bit': 0.0008633093525179857, 'none the': 0.0008633093525179857, 'about to': 0.006618705035971223, 'very busy': 0.002302158273381295, 'one of': 0.006618705035971223, 'convinced that': 0.01525179856115108, 'prepared to': 0.005179856115107914, 'afraid there': 0.0011510791366906475, 'much indebted': 0.002302158273381295, 'wrong shall': 0.0011510791366906475, 'six feet': 0.0011510791366906475, 'going out': 0.005179856115107914, 'indeed pleased': 0.0011510791366906475, 'as you': 0.002302158273381295, 'the wife': 0.002014388489208633, 'sorry to': 0.014100719424460431, 'sure that': 0.04402877697841727, 'right what': 0.0011510791366906475, 'sorry he': 0.0011510791366906475, 'very glad': 0.004316546762589928, 'concerned i': 0.0011510791366906475, 'willing to': 0.0031654676258992807, 'not sure': 0.006330935251798561, 'the judge': 0.0011510791366906475, 'baffled until': 0.0011510791366906475, 'not mistaken': 0.00460431654676259, 'lost without': 0.0011510791366906475, 'the king': 0.0011510791366906475, 'not accustomed': 0.002302158273381295, 'but thirty': 0.0011510791366906475, 'sure and': 0.002014388489208633, 'sure you': 0.005179856115107914, 'following you': 0.0011510791366906475, 'likely to': 0.0011510791366906475, 'your man': 0.0011510791366906475, 'to be': 0.002014388489208633, 'to remain': 0.0011510791366906475, 'inclined to': 0.008345323741007195, 'still in': 0.002302158273381295, 'all impatience': 0.0011510791366906475, 'in hopes': 0.002302158273381295, 'mr holmes': 0.0011510791366906475, 'sorry that': 0.0060431654676258995, 'glad to': 0.013237410071942447, 'immensely indebted': 0.0011510791366906475, 'very much': 0.00920863309352518, 'able to': 0.0057553956834532375, 'forced to': 0.0011510791366906475, 'so candid': 0.0011510791366906475, 'a widower': 0.002302158273381295, 'a very': 0.0028776978417266188, 'sure excuse': 0.0028776978417266188, 'myself one': 0.0011510791366906475, 'going through': 0.002302158273381295, 'not more': 0.0011510791366906475, 'afraid so': 0.0011510791366906475, 'just hold': 0.0011510791366906475, 'amply repaid': 0.0011510791366906475, 'not convinced': 0.0057553956834532375, 'much mistaken': 0.007194244604316547, 'staying with': 0.0011510791366906475, 'afraid that': 0.018992805755395685, 'a little': 0.005179856115107914, 'not quite': 0.002302158273381295, 'delighted to': 0.006618705035971223, 'to go': 0.0011510791366906475, 'afraid said': 0.002302158273381295, 'boasting when': 0.0011510791366906475, 'afraid not': 0.002302158273381295, 'so glad': 0.006906474820143885, 'sure was': 0.0011510791366906475, 'afraid the': 0.0011510791366906475, 'ashamed of': 0.0011510791366906475, 'not of': 0.0011510791366906475, 'convinced now': 0.0011510791366906475, 'still a': 0.0011510791366906475, 'a practical': 0.002302158273381295, 'arrested it': 0.0011510791366906475, 'no official': 0.0011510791366906475, 'acting in': 0.0011510791366906475, 'a dying': 0.0011510791366906475, 'faced by': 0.002014388489208633, 'tempted to': 0.0011510791366906475, 'not intruding': 0.0011510791366906475, 'the last': 0.002014388489208633, 'armed that': 0.0011510791366906475, 'so frightened': 0.002302158273381295, 'but youve': 0.0011510791366906475, 'all off': 0.0011510791366906475, 'in the': 0.00460431654676259, 'staying there': 0.0011510791366906475, 'all in': 0.0011510791366906475, 'sure forgive': 0.0011510791366906475, 'an old': 0.0011510791366906475, 'not hysterical': 0.0011510791366906475, 'not very': 0.005467625899280576, 'not joking': 0.0011510791366906475, 'mr neville': 0.0011510791366906475, 'illegally detained': 0.0011510791366906475, 'sure make': 0.0011510791366906475, 'sure mr': 0.0011510791366906475, 'very stupid': 0.0011510791366906475, 'at a': 0.002302158273381295, 'somewhat of': 0.0011510791366906475, 'when i': 0.0011510791366906475, 'right but': 0.0011510791366906475, 'in this': 0.002014388489208633, 'going mad': 0.0011510791366906475, 'myself and': 0.0011510791366906475, 'myself a': 0.0011510791366906475, 'not retained': 0.0011510791366906475, 'commuting a': 0.0011510791366906475, 'saving a': 0.0011510791366906475, 'sure wish': 0.0011510791366906475, 'all attention': 0.002302158273381295, 'living with': 0.0011510791366906475, 'a light': 0.002302158273381295, 'in town': 0.0011510791366906475, 'dr grimesby': 0.0011510791366906475, 'a dangerous': 0.0011510791366906475, 'safe from': 0.0011510791366906475, 'now sleeping': 0.0011510791366906475, 'in your': 0.0034532374100719426, 'no doubt': 0.0011510791366906475, 'now about': 0.002302158273381295, 'an orphan': 0.0011510791366906475, 'a hydraulic': 0.0011510791366906475, 'somewhat headstrong': 0.0011510791366906475, 'for west': 0.0011510791366906475, 'for north': 0.0011510791366906475, 'descending i': 0.0011510791366906475, 'afraid holmes': 0.0011510791366906475, 'surprised that': 0.0011510791366906475, 'very angry': 0.0011510791366906475, 'very sorry': 0.002302158273381295, 'a man': 0.0031654676258992807, 'alexander holder': 0.0011510791366906475, 'to do': 0.002302158273381295, 'giving you': 0.002014388489208633, 'myself to': 0.0011510791366906475, 'convinced from': 0.0011510791366906475, 'sure left': 0.0011510791366906475, 'endeavouring to': 0.002302158273381295, 'so sure': 0.0011510791366906475, 'exceptionally strong': 0.0011510791366906475, 'going right': 0.0011510791366906475, 'left to': 0.0011510791366906475, 'ever your': 0.0011510791366906475, 'saved i': 0.0011510791366906475, 'saved the': 0.0011510791366906475, 'bound to': 0.008920863309352519, 'very anxious': 0.0034532374100719426, 'sure said': 0.002014388489208633, 'sure your': 0.0011510791366906475, 'at my': 0.004316546762589928, 'so delighted': 0.0011510791366906475, 'not easy': 0.0011510791366906475, 'glad of': 0.002302158273381295, 'naturally observant': 0.0011510791366906475, 'sure if': 0.0011510791366906475, 'ready enough': 0.0011510791366906475, 'sure we': 0.002014388489208633, 'connected with': 0.0011510791366906475, 'innocent well': 0.0011510791366906475, 'very grateful': 0.0011510791366906475, 'perfectly satisfied': 0.002014388489208633, 'disappointed in': 0.0011510791366906475, 'sorry lancaster': 0.0011510791366906475, 'the pupil': 0.0011510791366906475, 'just slinging': 0.0011510791366906475, 'compelled to': 0.0037410071942446045, 'his its': 0.0008633093525179857, 'assured as': 0.0008633093525179857, 'no weakling': 0.0008633093525179857, 'familiar with': 0.002014388489208633, 'a doctor': 0.0017266187050359713, 'dull indeed': 0.0011510791366906475, 'always the': 0.0011510791366906475, 'not aware': 0.006330935251798561, 'as innocent': 0.0011510791366906475, 'the very': 0.0008633093525179857, 'to lodge': 0.0008633093525179857, 'not strong': 0.0008633093525179857, 'sulky when': 0.0008633093525179857, 'extremely lazy': 0.0008633093525179857, 'much obliged': 0.005179856115107914, 'the only': 0.0017266187050359713, 'generally able': 0.0008633093525179857, 'wrong look': 0.0008633093525179857, 'the most': 0.002014388489208633, 'his superior': 0.0008633093525179857, 'no chicken': 0.0008633093525179857, 'simply applying': 0.0008633093525179857, 'afraid rance': 0.0008633093525179857, 'rather in': 0.0008633093525179857, 'a widow': 0.0008633093525179857, 'afraid he': 0.0008633093525179857, 'as certain': 0.0008633093525179857, 'prepared for': 0.0008633093525179857, 'off lucy': 0.0008633093525179857, 'here again': 0.0008633093525179857, 'frightened dear': 0.0008633093525179857, 'the richer': 0.0008633093525179857, 'your elder': 0.0008633093525179857, 'jefferson hope': 0.0008633093525179857, 'off said': 0.0008633093525179857, 'thinking of': 0.0008633093525179857, 'i answered': 0.0008633093525179857, 'not likely': 0.002014388489208633, 'about done': 0.0008633093525179857, 'just as': 0.0008633093525179857, 'in my': 0.0008633093525179857, 'here at': 0.0017266187050359713, 'not subject': 0.0008633093525179857, 'miss morstan': 0.0008633093525179857, 'a great': 0.0008633093525179857, 'partial to': 0.0008633093525179857, 'myself ignorant': 0.0008633093525179857, 'gone after': 0.0008633093525179857, 'ashamed to': 0.0008633093525179857, 'sure in': 0.0008633093525179857, 'frightened my': 0.0008633093525179857, 'sure i': 0.004028776978417266, 'weaving my': 0.0008633093525179857, 'beginnin to': 0.0008633093525179857, 'sure sir': 0.002014388489208633, 'sorry mrs': 0.0008633093525179857, 'going down': 0.0008633093525179857, 'not tired': 0.0008633093525179857, 'surprised and': 0.0008633093525179857, 'perfectly fresh': 0.0008633093525179857, 'anxious she': 0.0008633093525179857, 'afraid for': 0.0008633093525179857, 'off down': 0.0008633093525179857, 'loath to': 0.0008633093525179857, 'in luck': 0.0017266187050359713, 'close on': 0.0008633093525179857, 'acting for': 0.0017266187050359713, 'sure of': 0.005467625899280576, 'taking a': 0.0008633093525179857, 'all right': 0.002014388489208633, 'dry i': 0.0008633093525179857, 'a worcestershire': 0.0008633093525179857, 'just making': 0.0008633093525179857, 'as ready': 0.0008633093525179857, 'with you': 0.0008633093525179857, 'once more': 0.0008633093525179857, 'keeping my': 0.0008633093525179857, 'telling you': 0.0031654676258992807, 'fond of': 0.0008633093525179857, 'a ruined': 0.0008633093525179857, 'of the': 0.0008633093525179857, 'afraid watson': 0.0011510791366906475, 'afraid a': 0.0011510791366906475, 'he asked': 0.002302158273381295, 'once upon': 0.0011510791366906475, 'delighted that': 0.0011510791366906475, 'quite at': 0.0011510791366906475, 'inclined now': 0.0011510791366906475, 'rather disappointed': 0.0011510791366906475, 'quite ready': 0.0011510791366906475, 'under obligations': 0.0011510791366906475, 'a married': 0.0011510791366906475, 'a hop': 0.0011510791366906475, 'your neighbor': 0.0011510791366906475, 'usually an': 0.0011510791366906475, 'quite myself': 0.0011510791366906475, 'determined well': 0.0011510791366906475, 'a better': 0.0011510791366906475, 'getting a': 0.0011510791366906475, 'very delighted': 0.0011510791366906475, 'perfectly willing': 0.0011510791366906475, 'an accountant': 0.0011510791366906475, 'here by': 0.0011510791366906475, 'out of': 0.0011510791366906475, 'afraid i': 0.0031654676258992807, 'sure but': 0.0011510791366906475, 'asking myself': 0.0011510791366906475, 'placed but': 0.0011510791366906475, 'generally recognized': 0.0011510791366906475, 'member for': 0.0011510791366906475, 'a bachelor': 0.002302158273381295, 'strong enough': 0.0011510791366906475, 'afraid however': 0.0011510791366906475, 'liable to': 0.0011510791366906475, 'here there': 0.0011510791366906475, 'afraid my': 0.002014388489208633, 'on the': 0.002302158273381295, 'utterly unable': 0.0011510791366906475, 'rather shaken': 0.0011510791366906475, 'only of': 0.0011510791366906475, 'quite wakeful': 0.0011510791366906475, 'investigating i': 0.0011510791366906475, 'keeping you': 0.0011510791366906475, 'absolved from': 0.0011510791366906475, 'the witness': 0.0011510791366906475, 'not who': 0.0011510791366906475, 'almost ashamed': 0.0011510791366906475, 'a london': 0.0011510791366906475, 'unduly singing': 0.0011510791366906475, 'sorry if': 0.0011510791366906475, 'doing he': 0.0011510791366906475, 'sure have': 0.0011510791366906475, 'speaking the': 0.0011510791366906475, 'an interpreter': 0.0011510791366906475, 'a greek': 0.0011510791366906475, 'principally associated': 0.0011510791366906475, 'sent for': 0.0011510791366906475, 'a stranger': 0.002014388489208633, 'clear again': 0.0011510791366906475, 'still so': 0.0011510791366906475, 'mistaken she': 0.0011510791366906475, 'the unconscious': 0.0011510791366906475, 'dying to': 0.0011510791366906475, 'afraid josephs': 0.0011510791366906475, 'satisfied that': 0.0011510791366906475, 'of what': 0.0011510791366906475, 'by no': 0.0011510791366906475, 'in positive': 0.0011510791366906475, 'quite sure': 0.002014388489208633, 'neglecting business': 0.0011510791366906475, 'well convinced': 0.002302158273381295, 'conscious that': 0.0011510791366906475, 'pleased to': 0.002302158273381295, 'a neighbour': 0.0011510791366906475, 'sure maybe': 0.0011510791366906475, 'overjoyed to': 0.0011510791366906475, 'full of': 0.0011510791366906475, 'correct colonel': 0.0011510791366906475, 'sure moran': 0.0011510791366906475, 'nearly mad': 0.0011510791366906475, 'the unhappy': 0.0011510791366906475, 'all that': 0.0011510791366906475, 'afraid entirely': 0.0011510791366906475, 'convinced of': 0.0011510791366906475, 'doing so': 0.0011510791366906475, 'dont you': 0.0011510791366906475, 'i ought': 0.0011510791366906475, 'only a': 0.002302158273381295, 'sure well': 0.0011510791366906475, 'justified in': 0.0011510791366906475, 'fairly familiar': 0.0011510791366906475, 'seated here': 0.0011510791366906475, 'sure it': 0.0011510791366906475, 'convinced she': 0.0011510791366906475, 'leaving mr': 0.0011510791366906475, 'asking you': 0.002014388489208633, 'bob carruthers': 0.0011510791366906475, 'mistaken as': 0.0011510791366906475, 'level with': 0.0011510791366906475, 'quite well': 0.0011510791366906475, 'retained in': 0.0011510791366906475, 'aware mr': 0.0011510791366906475, 'the founder': 0.0011510791366906475, 'not indiscreet': 0.0011510791366906475, 'not to': 0.002302158273381295, 'told that': 0.002014388489208633, 'convinced said': 0.0011510791366906475, 'sorry but': 0.0011510791366906475, 'correctly informed': 0.0011510791366906475, 'disposed to': 0.0011510791366906475, 'right glad': 0.0011510791366906475, 'not in': 0.0031654676258992807, 'a poor': 0.0011510791366906475, 'of course': 0.0011510791366906475, 'aware that': 0.004316546762589928, 'armed to': 0.0011510791366906475, 'perfectly prepared': 0.0011510791366906475, 'engaged my': 0.0011510791366906475, 'a plumber': 0.0011510791366906475, 'never precipitate': 0.0011510791366906475, 'so confused': 0.0011510791366906475, 'giving away': 0.0011510791366906475, 'going round': 0.0011510791366906475, 'gathering all': 0.0011510791366906475, 'exceedingly obliged': 0.002014388489208633, 'an honest': 0.002014388489208633, 'a methodical': 0.0011510791366906475, 'of opinion': 0.0011510791366906475, 'wrong and': 0.0011510791366906475, 'myself holmes': 0.0011510791366906475, 'a connoisseur': 0.0011510791366906475, 'utterly mistaken': 0.0011510791366906475, 'not yet': 0.0011510791366906475, 'aware of': 0.0031654676258992807, 'here she': 0.0011510791366906475, 'your prisoner': 0.0011510791366906475, 'this mans': 0.002302158273381295, 'going i': 0.0011510791366906475, 'happy to': 0.002014388489208633, 'the skipper': 0.0011510791366906475, 'a private': 0.0011510791366906475, 'cyril overton': 0.0011510791366906475, 'all the': 0.0011510791366906475, 'not responsible': 0.0011510791366906475, 'in agreement': 0.0011510791366906475, 'but you': 0.0011510791366906475, 'not employed': 0.0011510791366906475, 'concerned and': 0.0011510791366906475, 'much more': 0.0011510791366906475, 'certain i': 0.0011510791366906475, 'sure think': 0.0011510791366906475, 'able all': 0.0011510791366906475, 'thankful madam': 0.0011510791366906475, 'going far': 0.0011510791366906475, 'here the': 0.0011510791366906475, 'that the': 0.0011510791366906475, 'fairly justified': 0.0008633093525179857, 'so very': 0.0008633093525179857, 'addressing and': 0.0008633093525179857, 'in mine': 0.0008633093525179857, 'myself an': 0.0008633093525179857, 'suddenly confronted': 0.0008633093525179857, 'myself yet': 0.0008633093525179857, 'telling that': 0.0008633093525179857, 'presuming that': 0.0008633093525179857, 'almost certain': 0.0008633093525179857, 'going back': 0.0008633093525179857, 'conscious always': 0.0008633093525179857, 'wearing last': 0.0008633093525179857, 'of one': 0.0008633093525179857, 'stapleton of': 0.0008633093525179857, 'naturally curious': 0.0008633093525179857, 'simply here': 0.0008633093525179857, 'justly reproved': 0.0008633093525179857, 'all this': 0.0008633093525179857, 'never dull': 0.0008633093525179857, 'about the': 0.0008633093525179857, 'sir henrys': 0.0008633093525179857, 'no antiquarian': 0.0008633093525179857, 'certain that': 0.0017266187050359713, 'making up': 0.0008633093525179857, 'well you': 0.0008633093525179857, 'glad that': 0.0008633093525179857, 'really in': 0.0008633093525179857, 'a coward': 0.0008633093525179857, 'conscious myself': 0.0008633093525179857, 'his agent': 0.0008633093525179857, 'certainly developing': 0.0008633093525179857, 'sorry madam': 0.0008633093525179857, 'proud to': 0.0008633093525179857, 'entitled the': 0.0008633093525179857, 'glad from': 0.0008633093525179857, 'already aware': 0.0008633093525179857, 'more to': 0.0008633093525179857, 'investigating the': 0.0008633093525179857, 'reckoned fleet': 0.0008633093525179857, 'spared by': 0.0008633093525179857, 'told which': 0.0008633093525179857, 'powerless but': 0.0008633093525179857, 'sure agree': 0.0008633093525179857, 'interested but': 0.0008633093525179857, 'not surprised': 0.0008633093525179857, 'saying has': 0.0008633093525179857, 'too occupied': 0.0008633093525179857, 'any judge': 0.0008633093525179857, 'relieved but': 0.0008633093525179857, 'mistaken and': 0.0008633093525179857, 'not out': 0.0017266187050359713, 'certain but': 0.0008633093525179857, 'convinced myself': 0.0008633093525179857, 'sure they': 0.0017266187050359713, 'sure can': 0.0008633093525179857, 'still at': 0.0008633093525179857, 'only awaiting': 0.0008633093525179857, 'not at': 0.002014388489208633, 'here to': 0.0034532374100719426, 'informed the': 0.0008633093525179857, 'the dramatist': 0.0008633093525179857, 'myself at': 0.0008633093525179857, 'assured that': 0.0008633093525179857, 'alive and': 0.0008633093525179857, 'wearing one': 0.0008633093525179857, 'mcmurdo answered': 0.0008633093525179857, 'a judge': 0.0008633093525179857, 'a member': 0.0008633093525179857, 'counting upon': 0.0008633093525179857, 'as bad': 0.0008633093525179857, 'in no': 0.0008633093525179857, 'cried mcmurdo': 0.0008633093525179857, 'through with': 0.0008633093525179857, 'no better': 0.0008633093525179857, 'safe in': 0.0008633093525179857, 'the chief': 0.0008633093525179857, 'well ive': 0.0008633093525179857, 'are you': 0.0008633093525179857, 'take a': 0.0008633093525179857, 'said mcmurdo': 0.0008633093525179857, 'a faithful': 0.0008633093525179857, 'sorry i': 0.0008633093525179857, 'a newcomer': 0.0008633093525179857, 'strange to': 0.0008633093525179857, 'loyal to': 0.0008633093525179857, 'a good': 0.0008633093525179857, 'excommunicated from': 0.0008633093525179857, 'too busy': 0.0008633093525179857, 'on duty': 0.0008633093525179857, 'not married': 0.0008633093525179857, 'to hear': 0.0008633093525179857, 'near out': 0.0008633093525179857, 'the bearer': 0.0008633093525179857, 'little more': 0.0008633093525179857, 'birdy edwards': 0.0017266187050359713, 'at last': 0.0008633093525179857, 'the winner': 0.0008633093525179857, 'mistaken is': 0.0011510791366906475, 'we have': 0.0011510791366906475, 'suspected a': 0.0011510791366906475, 'doing oh': 0.0011510791366906475, 'beyond their': 0.0011510791366906475, 'as amazed': 0.0011510791366906475, 'a quiet': 0.0011510791366906475, 'convinced sir': 0.0011510791366906475, 'coming to': 0.0011510791366906475, 'weary of': 0.0011510791366906475, 'not good': 0.0011510791366906475, 'but he': 0.0011510791366906475, 'all alone': 0.0011510791366906475, 'emilia lucca': 0.0011510791366906475, 'going for': 0.0011510791366906475, 'to have': 0.0011510791366906475, 'going this': 0.0011510791366906475, 'somewhat exhausted': 0.0011510791366906475, 'wondering strange': 0.0011510791366906475, 'sorry said': 0.002014388489208633, 'of disease': 0.0011510791366906475, 'here coals': 0.0011510791366906475, 'dressed for': 0.0011510791366906475, 'somewhat upon': 0.0011510791366906475, 'in touch': 0.0011510791366906475, 'you have': 0.0011510791366906475, 'as sure': 0.002014388489208633, 'not clear': 0.0028776978417266188, 'an early': 0.0011510791366906475, 'very sure': 0.0011510791366906475, 'really very': 0.0011510791366906475, 'a born': 0.0011510791366906475, 'taking no': 0.0011510791366906475, 'but since': 0.0011510791366906475, 'bound therefore': 0.0008633093525179857, 'acting i': 0.0008633093525179857, 'accustomed to': 0.0008633093525179857, 'perfectly certain': 0.0008633093525179857, 'turning my': 0.0008633093525179857, 'adelbert gruner': 0.0008633093525179857, 'not often': 0.0008633093525179857, 'she cried': 0.0008633093525179857, 'his last': 0.0008633093525179857, 'before you': 0.0008633093525179857, 'assured of': 0.0008633093525179857, 'not compelled': 0.0008633093525179857, 'content to': 0.0008633093525179857, 'might i': 0.0008633093525179857, 'a brain': 0.0008633093525179857, 'out for': 0.0008633093525179857, 'here i': 0.0008633093525179857, 'right on': 0.0008633093525179857, 'concerned you': 0.0008633093525179857, 'drawing the': 0.0008633093525179857, 'quite comfortable': 0.0008633093525179857, 'a busy': 0.002589928057553957, 'bewildered but': 0.0008633093525179857, 'acting this': 0.0008633093525179857, 'very far': 0.0008633093525179857, 'confident we': 0.0008633093525179857, 'more uneasy': 0.0008633093525179857, 'your debtor': 0.0008633093525179857, 'sir faithfully': 0.0008633093525179857, 'getting into': 0.0008633093525179857, 'are for': 0.0008633093525179857, 'manager of': 0.0008633093525179857, 'in need': 0.0008633093525179857, 'a rather': 0.0008633093525179857, 'said holmes': 0.0008633093525179857, 'i guess': 0.0008633093525179857, 'in closer': 0.0008633093525179857, 'in a': 0.0008633093525179857, 'very serious': 0.0008633093525179857, 'investigating it': 0.0008633093525179857, 'looking for': 0.0008633093525179857, 'very likely': 0.0008633093525179857, 'sure understand': 0.0008633093525179857, 'as as': 0.0008633093525179857, 'holmes looked': 0.0008633093525179857, 'sorry professor': 0.0008633093525179857, 'so sorry': 0.0008633093525179857, 'mistaken next': 0.0008633093525179857, 'a swimmer': 0.0008633093525179857, 'your subordinate': 0.0008633093525179857, 'fairly up': 0.0008633093525179857, 'if i': 0.0008633093525179857, 'ready said': 0.0008633093525179857, 'an omnivorous': 0.0008633093525179857, 'quite satisfied': 0.0008633093525179857, 'gone all': 0.0008633093525179857, 'a responsible': 0.0008633093525179857, 'unfolding but': 0.0008633093525179857, 'a myself': 0.0008633093525179857, 'running a': 0.0008633093525179857, 'dependent upon': 0.0008633093525179857, 'deeply in': 0.0008633093525179857, 'preoccupied with': 0.0008633093525179857, 'quite impersonal': 0.0008633093525179857, 'expecting him': 0.0008633093525179857, 'little purlington': 0.0008633093525179857, 'sure amberley': 0.0008633093525179857}\n"
     ]
    }
   ],
   "source": [
    "print(f\"All possible transitions from 'i am' state: \\n {markov_model['i am']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34a6996",
   "metadata": {},
   "source": [
    "## Generating SH Stories\n",
    "\n",
    "**Get Ready**: Imagine you have a book (Markov model) that tells you which words come after other words. You want to use this book to write a new story.\n",
    "\n",
    "**Start the Story**: Begin by writing a sentence based on a starting word. This word is your \"current state\".\n",
    "\n",
    "**Write a New Sentence**: Keep writing more sentences based on the words that usually come after your current word. Pick the next word by looking at the chances (probabilities) given in your book.\n",
    "\n",
    "**Repeat**: Keep writing more sentences until you've reached the desired story length.\n",
    "\n",
    "**Finished!**: You now have a new story that sounds like the original data.\n",
    "\n",
    "Let's use the same example and build upon it:\n",
    "\n",
    "Suppose we have the Markov model built from before:\n",
    "\n",
    "`{'A': {'B': 1.0},\n",
    " 'B': {'C': 1.0, 'D': 0.5, 'A': 0.5},\n",
    " 'C': {'A': 1.0}}`\n",
    "\n",
    "And now, we're using the story_generator function to create a new story based on this model:\n",
    "\n",
    "* You're getting ready to use your book (Markov model).\n",
    "* You start your story with the sentence \"my god\".\n",
    "* You look at your book for \"my god\" and see that the next word is usually \"is\". So, you write \"my god is\".\n",
    "* You continue looking at your book. Since you've written \"my god is\", you check your book for \"is\" and see that \"this\" usually follows. So, you write \"my god is this\".\n",
    "* You keep following your book and write the next words based on the chances given. If there's more than one option, you choose according to the probabilities.\n",
    "* This continues until you've written enough sentences to reach the desired story length. You're using your Markov model to guide your writing, creating a new story that sounds like it could have come from the original data.\n",
    "\n",
    "Here's an example of a possible generated story:\n",
    "\n",
    "`my god is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example hello world is this a simple example\n",
    "`\n",
    "\n",
    "Please note that the generated story might vary each time you run the function due to the random choices made based on the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a458f59f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T13:17:59.375307Z",
     "start_time": "2023-08-17T13:17:59.368781Z"
    }
   },
   "outputs": [],
   "source": [
    "def story_generator(markov_model, limit=150, start='my god'):\n",
    "    n = 0\n",
    "    current_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story += current_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[current_state].keys()),\n",
    "                                   list(markov_model[current_state].values()))\n",
    "        current_state = next_state[0]\n",
    "        story += current_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3bc9617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T13:21:09.311636Z",
     "start_time": "2023-08-17T13:21:09.283593Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Story 0: he has them hidden in a moment from his face was haggard and thin and eager stamped with .\n",
      "Story 1: he has not been devoid of excitement when i say criminal because only a few hundred yards i .\n",
      "Story 2: he has been called upon to interfere our investigation has served to show me the letter across it .\n",
      "Story 3: oh no or to make myself as pitiable as possible i shall enumerate them to you in solving .\n",
      "Story 4: the thing for which this man mcmurdo was a man answered by another hoot at a cabby we .\n",
      "Story 5: it was clear to me then how is it then your brother held and that you saw all .\n",
      "Story 6: he has amassed a fortune at last there is a bachelor years of age which is very rare .\n",
      "Story 7: the thing which she had given an exclamation of satisfaction he bent forward and the paper upon the .\n",
      "Story 8: the thing always appears to me by one the articles found his chubby face and his thin hands .\n",
      "Story 9: the thing however is an old trick that you are close to him for some time but sir .\n",
      "Story 10: no sir nothing what became of him it is obvious that the law was a short walk brought .\n",
      "Story 11: you made anything out yet she had left it i would carry my stone to kilburn there was .\n",
      "Story 12: you made an inventory first you will have done good heavens holmes do you suppose that it is .\n",
      "Story 13: my god it is attached to the wire just to see her i should have expected some bleeding .\n",
      "Story 14: he has lost some years ago a very lonely man i had followed at their heels sometimes i .\n",
      "Story 15: the thing is beyond humanity it is certainly a chance that the height of selfishness if he were .\n",
      "Story 16: it was only last night that was the cry of surprise and delight everything was as ghastly as .\n",
      "Story 17: my god he cried give it up until holmess hand was on her bed this morning with her .\n",
      "Story 18: he has been in his service for years from an english firm what do you make of that .\n",
      "Story 19: you made any inquiries as to money well yes of course there are the regulars so the auxiliary .\n"
     ]
    }
   ],
   "source": [
    "choice_list = ['my god', 'oh no', 'he has', 'no sir', 'it was', 'you made', 'the thing']\n",
    "\n",
    "for i in range(20):\n",
    "    print(f\"Story {i}: {story_generator(markov_model, limit=8, start= random.choice(choice_list))}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4710be0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T13:21:36.807409Z",
     "start_time": "2023-08-17T13:21:36.569597Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: pathspec 'the' did not match any file(s) known to git\n",
      "error: pathspec 'Markov' did not match any file(s) known to git\n",
      "error: pathspec 'Model' did not match any file(s) known to git\n",
      "error: pathspec 'for' did not match any file(s) known to git\n",
      "error: pathspec 'story' did not match any file(s) known to git\n",
      "error: pathspec 'generation'' did not match any file(s) known to git\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc111111",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
